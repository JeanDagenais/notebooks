{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best way to create residuals in a convolution network? \n",
    "This notebook shows two different ways to create residual shortcuts in your network that can presumably improve the effectiveness of backpropagation through the network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the advantages of each method?\n",
    "2. What is the best practice for reshaping 3D tensors to a standard size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, SimpleRNN, Reshape, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use convolution layers as residual shortcut.\n",
    "\n",
    "This example shows how 3D tensors from convolution layers can be used as residual shortcuts. The difficult part of this method is keeping the shapes of the tensors the same size as the convolved tensors become narrower and deeper. There are several examples showing how an extra 1x1 convolution  layer can be used to match the size of the residual tensors. \n",
    "* [Keras Resnet](https://github.com/raghakot/keras-resnet/blob/master/resnet.py#L41)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "img_in (InputLayer)              (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Convolution2D)            (None, 39, 52, 64)    6976        img_in[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_222 (Dropout)            (None, 39, 52, 64)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Convolution2D)            (None, 39, 52, 64)    36928       dropout_222[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_223 (Dropout)            (None, 39, 52, 64)    0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_217 (Dense)                (None, 39, 52, 64)    4160        dropout_223[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "aux1 (Dense)                     (None, 39, 52, 64)    4160        dropout_222[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_45 (Merge)                 (None, 39, 52, 64)    0           dense_217[0][0]                  \n",
      "                                                                   aux1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)             (None, 129792)        0           merge_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "angle_out (Dense)                (None, 1)             129793      flatten_22[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 182,017\n",
      "Trainable params: 182,017\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "\n",
    "net =  Convolution2D(64, 6, 6, subsample=(3,3), name='conv1')(img_in)\n",
    "net =  Dropout(.2)(net)\n",
    "aux1 = Dense(64, name='aux1')(net)\n",
    "\n",
    "net =  Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same', name='conv2')(net)\n",
    "net =  Dropout(.2)(net)\n",
    "\n",
    "net = Dense(64)(net)\n",
    "\n",
    "net = merge([net, aux1], mode='sum')\n",
    "net = Flatten()(net)\n",
    "angle_out = Dense(1, name='angle_out')(net)\n",
    "model = Model(input=[img_in], output=[angle_out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using flat+dense layers as residual shortcut\n",
    "Another way to create a residual shortcut is to flatten the tensor and use a dense layer to standardize it's size. This method has an order of magnitude more parameters to train but is easy to implement. This method was used in the [vision module](https://github.com/udacity/self-driving-car/blob/master/steering-models/community-models/komanda/solution-komanda.ipynb) of winner of the last Udacity Self Driving Car steering angle challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "img_in (InputLayer)              (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv0 (Convolution2D)            (None, 39, 52, 64)    6976        img_in[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_228 (Dropout)            (None, 39, 52, 64)    0           conv0[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Convolution2D)            (None, 20, 26, 128)   73856       dropout_228[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_229 (Dropout)            (None, 20, 26, 128)   0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 66560)         0           dropout_229[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "aux1_flat (Flatten)              (None, 129792)        0           dropout_228[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_220 (Dense)                (None, 64)            4259904     flatten_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "aux1_dense (Dense)               (None, 64)            8306752     aux1_flat[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_48 (Merge)                 (None, 64)            0           dense_220[0][0]                  \n",
      "                                                                   aux1_dense[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "angle_out (Dense)                (None, 1)             65          merge_48[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 12,647,553\n",
      "Trainable params: 12,647,553\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "\n",
    "net =  Convolution2D(64, 6, 6, subsample=(3,3), name='conv0')(img_in)\n",
    "net =  Dropout(.2)(net)\n",
    "\n",
    "#Create residual to shortcut\n",
    "aux1 = Flatten(name='aux1_flat')(net)\n",
    "aux1 = Dense(64, name='aux1_dense')(aux1) \n",
    "\n",
    "net =  Convolution2D(128, 3, 3, subsample=(2,2), border_mode='same', name='conv2')(net)\n",
    "net =  Dropout(.2)(net)\n",
    "net = Flatten()(net)\n",
    "net = Dense(64)(net)\n",
    "\n",
    "net = merge([net, aux1], mode='sum')\n",
    "\n",
    "angle_out = Dense(1, name='angle_out')(net)\n",
    "model = Model(input=[img_in], output=[angle_out])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
